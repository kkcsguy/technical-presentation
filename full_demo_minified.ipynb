{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa50edf1",
   "metadata": {},
   "source": [
    "# COVID Tweet Analysis Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6786636d",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from wordcloud import WordCloud\n",
    "from typing import Union, List, Callable\n",
    "import pickle\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize, RegexpTokenizer\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "import re\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b562c44d",
   "metadata": {},
   "source": [
    "## Interactive Macro Trend Analysis\n",
    "\n",
    "#### Core Functionality \n",
    "Understand the <u>macro trends</u> of COVID-19 communication from tweet data.\n",
    "1) Most common words in tweets \n",
    "2) Length of tweets\n",
    "3) Number of tweets\n",
    "\n",
    "Everything plot can be filtered by <u>Date Range</u> and <u>Location</u>.\n",
    "\n",
    "#### Choices and Impact \n",
    "COVID-19 is a global issue, so health organizations *must* be able to choose to analyze trends in communication across both time and location. \n",
    "\n",
    "- Due to the scope of COVID-19, analysis can't be done on all areas at once. \n",
    "- Instead $\\longrightarrow$ give organization the ability to decide where to focus their efforts\n",
    "\n",
    "##### Examples\n",
    "\n",
    "- Visualize how many #COVID19 tweets are coming from the United States vs other countries\n",
    "\n",
    "\n",
    "- What are the most common words being used in tweets in the United States in March 2020? \n",
    "    - What about August 2020?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55ef9b94",
   "metadata": {
    "code_folding": [
     0,
     1,
     54,
     77,
     95,
     141,
     170
    ]
   },
   "outputs": [],
   "source": [
    "# Preprocessing Helper Functions\n",
    "def preprocess_text(text: str) -> str:\n",
    "    \n",
    "    \"\"\"\n",
    "    Processes a tweet string by removing any weird string characters/formattings\n",
    "    Args: \n",
    "        - text (str): the text to clean\n",
    "    Returns: \n",
    "        - clean_text (str): the cleaned text string\n",
    "    \"\"\"\n",
    "    # convert to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # remove numbers\n",
    "    text = re.sub(r\"\\d\", \"\", text)\n",
    "    \n",
    "    # remove punctuation\n",
    "    text = re.sub(r\"[^\\w\\s]\", \"\", text)\n",
    "    \n",
    "    # remove stopwords\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    \n",
    "    # Removing extra spaces\n",
    "    text = \" \".join(tokens)\n",
    "    text = re.sub(' +', ' ', text)\n",
    "    \n",
    "    # remove URLs\n",
    "    text = re.sub(r\"http\\S+\", \"\", text)\n",
    "\n",
    "    # Removing Emojis\n",
    "    text = re.sub(r'[^\\x00-\\x7F]+', '', text)\n",
    "    \n",
    "    # Removing emoticons\n",
    "    text = re.sub(r':\\w+:', '', text)\n",
    "    text = re.sub(r'[^\\x00-\\x7F]+', '', text)\n",
    "    \n",
    "    # Removing Contractions\n",
    "    text = re.sub(r\"can\\'t\", \"can not\", text)\n",
    "    text = re.sub(r\"won\\'t\", \"will not\", text)\n",
    "    text = re.sub(r\"n\\'t\", \" not\", text)\n",
    "    text = re.sub(r\"\\'re\", \" are\", text)\n",
    "    text = re.sub(r\"\\'s\", \" is\", text)\n",
    "    text = re.sub(r\"\\'d\", \" would\", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will\", text)\n",
    "    text = re.sub(r\"\\'t\", \" not\", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have\", text)\n",
    "    text = re.sub(r\"\\'m\", \" am\", text)\n",
    "    \n",
    "    clean_text = text\n",
    "    \n",
    "    return clean_text\n",
    "\n",
    "def preprocess_nulls(df: pd.DataFrame) -> pd.DataFrame: \n",
    "    \n",
    "    \"\"\"\n",
    "    Removes nulls and 0 counts from a dataframe\n",
    "    Args: \n",
    "        - df (pd.DataFrame): the dataframe to remove nulls from\n",
    "    Returns: \n",
    "        - clean_df (str): the cleaned df\n",
    "    \"\"\"\n",
    "    \n",
    "    # Drop duplicate rows \n",
    "    df = df.drop_duplicates(subset = \"text\")\n",
    "    \n",
    "    # Drop rows with no followers \n",
    "    df = df[df['user_followers'] > 0]\n",
    "    \n",
    "    # Drop nulls and reset index \n",
    "    df = df.dropna().reset_index(drop = True)\n",
    "    \n",
    "    clean_df = df\n",
    "    \n",
    "    return clean_df\n",
    "\n",
    "def preprocess_df(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \n",
    "    \"\"\"\n",
    "    Main processing function on the dataframe\n",
    "    Args: \n",
    "        - df (pd.DataFrame): df of tweets to process\n",
    "    Returns: \n",
    "        - preprocessed_df (pd.DataFrame): the processed df\n",
    "    \"\"\"\n",
    "    \n",
    "    # Preprocess null and missing values \n",
    "    df = preprocess_nulls(df)\n",
    "    \n",
    "    # Preprocess text \n",
    "    df['processed_text'] = df['text'].apply(preprocess_text)            \n",
    "    \n",
    "    return df\n",
    "\n",
    "def create_widget(): \n",
    "    \n",
    "    \"\"\"\n",
    "    Creates the widget options and returns them\n",
    "    \"\"\"\n",
    "    \n",
    "    # Dropdown menu to choose the plot\n",
    "    plot_options = ['Bar Plot of Most Common Words in Tweets', 'Distribution of Length of Tweets', 'Time-series Plot of Tweet Counts', 'Word Cloud of Most Common Words']\n",
    "    plot_dropdown = widgets.Dropdown(\n",
    "        options=plot_options,\n",
    "        value=plot_options[0],\n",
    "        description='Select Plot:',\n",
    "    )\n",
    "\n",
    "    # Dropdown menu to choose the country\n",
    "    country_options = ['All Countries', 'United States', 'Canada', 'South Africa','Switzerland','London','India','United Kingdom']\n",
    "    country_dropdown = widgets.Dropdown(\n",
    "        options=country_options,\n",
    "        value=country_options[0],\n",
    "        description='Country:',\n",
    "    )\n",
    "\n",
    "    # Date range picker\n",
    "    start_date_picker = widgets.DatePicker(\n",
    "        description='Start Date',\n",
    "        disabled=False\n",
    "    )\n",
    "\n",
    "    end_date_picker = widgets.DatePicker(\n",
    "        description='End Date',\n",
    "        disabled=False\n",
    "    )\n",
    "\n",
    "\n",
    "    # Button to process the dataset and generate the plot\n",
    "    process_button = widgets.Button(\n",
    "        description='Plot',\n",
    "        tooltip='Plot',\n",
    "    )\n",
    "\n",
    "    # Output widget to display the result\n",
    "    output = widgets.Output()\n",
    "    \n",
    "    \n",
    "    return plot_dropdown, country_dropdown, start_date_picker, end_date_picker, process_button, output\n",
    "\n",
    "def load_process_data(file_path): \n",
    "    \n",
    "    \"\"\"\n",
    "    Loads data and logs if successful\"\"\"\n",
    "    \n",
    "    try: \n",
    "        df = pd.read_csv(file_path)\n",
    "    except: \n",
    "        print('Could not load data')\n",
    "        return\n",
    "\n",
    "    # Convert to date\n",
    "    df['date'] = pd.to_datetime(df['date']).dt.date\n",
    "\n",
    "\n",
    "    # Log the output\n",
    "    min_date = df['date'].min().strftime('%m/%d/%Y')\n",
    "    max_date = df['date'].max().strftime('%m/%d/%Y')\n",
    "    print(\"\\nData is loaded successfully\")\n",
    "    print(f'   Earliest Tweet Date: {min_date}')\n",
    "    print(f'   Latest Tweet Date: {max_date}')\n",
    "\n",
    "\n",
    "    # Preprocess dataset\n",
    "    preprocessed_df = preprocess_df(df)\n",
    "    print(\"\\nYour data is ready for analysis.\")\n",
    "    \n",
    "    return preprocessed_df\n",
    "\n",
    "def filter_df(preprocessed_df, country_dropdown, start_date_picker, end_date_picker): \n",
    "    \n",
    "    \"\"\"\n",
    "    Filters the DF based on rules from the dropdowns and option widgets\n",
    "    \"\"\"\n",
    "    \n",
    "    # Filter tweets by country\n",
    "    selected_country = country_dropdown.value\n",
    "    if selected_country != 'All Countries':\n",
    "        filtered_df = preprocessed_df.loc[preprocessed_df['user_location'] == selected_country]\n",
    "    else:\n",
    "        filtered_df = preprocessed_df\n",
    "\n",
    "\n",
    "    filtered_df['date'] = pd.to_datetime(filtered_df['date'])\n",
    "\n",
    "    start_date = start_date_picker.value\n",
    "    end_date = end_date_picker.value\n",
    "    if start_date and end_date:\n",
    "        start_date = pd.to_datetime(start_date)\n",
    "        end_date = pd.to_datetime(end_date)\n",
    "        filtered_df = filtered_df[(filtered_df['date'] >= start_date) & (filtered_df['date'] <= end_date)]\n",
    "        \n",
    "    return filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e03e087c",
   "metadata": {
    "code_folding": [
     0,
     22,
     32,
     43,
     56
    ]
   },
   "outputs": [],
   "source": [
    "# Plotting Helper Functions\n",
    "def generate_bar_plot(filtered_df): \n",
    "    \n",
    "    \"\"\"\n",
    "    Bar plot\n",
    "    \"\"\"\n",
    "    # code for bar plot\n",
    "    text = \" \".join(filtered_df['processed_text'])\n",
    "    words = text.split()\n",
    "    words_counter = Counter(words)\n",
    "    most_common_words = words_counter.most_common(20)\n",
    "\n",
    "    words = [word[0] for word in most_common_words]\n",
    "    counts = [word[1] for word in most_common_words]\n",
    "\n",
    "    plt.barh(words, counts)\n",
    "    plt.xlabel('Words')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('Bar Plot of Most Common Words in Tweets')\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.show()\n",
    "\n",
    "def generate_tweet_length_plot(filtered_df): \n",
    "    \n",
    "    # code for length distribution plot\n",
    "    filtered_df['text_length'] = filtered_df['text'].apply(len)\n",
    "    filtered_df['text_length'].plot.hist(bins=30, rwidth=0.9)\n",
    "    plt.xlabel('Length of Tweets')\n",
    "    plt.ylabel('Counts')\n",
    "    plt.title('Distribution of Length of Tweets')\n",
    "    plt.show()\n",
    "\n",
    "def generate_time_series_plot(filtered_df): \n",
    "    # code for time-series plot\n",
    "        filtered_df['date'] = pd.to_datetime(filtered_df['date'])\n",
    "        df_grouped = filtered_df.groupby(filtered_df['date'].dt.date).count()\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.plot(df_grouped.index, df_grouped['text'])\n",
    "        ax.set_ylabel('Number of Tweets')\n",
    "        ax.set_title('Time-series Plot of Tweet Counts')\n",
    "        plt.xticks(rotation=90)\n",
    "        plt.show()\n",
    "\n",
    "def generate_word_cloud(filtered_df): \n",
    "    \n",
    "    # code for word cloud\n",
    "        text = \" \".join(filtered_df['processed_text'])\n",
    "        words = text.split()\n",
    "        words_counter = Counter(words)\n",
    "        wordcloud = WordCloud(width=800, height=400).generate_from_frequencies(words_counter)\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.imshow(wordcloud, interpolation='bilinear')\n",
    "        plt.axis(\"off\")\n",
    "        plt.title('Word Cloud of Most Common Words')\n",
    "        plt.show()\n",
    "\n",
    "def generate_word_cloud_by_location(filtered_df): \n",
    "    \n",
    "    top_words_by_location = {}\n",
    "    for location in filtered_df['user_location'].unique():\n",
    "        location_df = filtered_df.loc[filtered_df['user_location'] == location]\n",
    "        text = \" \".join(location_df['processed_text'])\n",
    "        words = text.split()\n",
    "        words_counter = Counter(words)\n",
    "        most_common_words = words_counter.most_common(20)\n",
    "        top_words_by_location[location] = most_common_words\n",
    "        \n",
    "        \n",
    "     # Plot word cloud for each location\n",
    "    for location, top_words in top_words_by_location.items():\n",
    "        words = [word[0] for word in top_words]\n",
    "        frequencies = [word[1] for word in top_words]\n",
    "        wordcloud = WordCloud(width=800, height=400).generate_from_frequencies(dict(zip(words, frequencies)))\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.imshow(wordcloud, interpolation='bilinear')\n",
    "        plt.axis(\"off\")\n",
    "        plt.title(f'Most Common Words in Tweets from {location}')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85850117",
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please enter the path to your CSV file: ../data/covid2020.csv\n",
      "\n",
      "Data is loaded successfully\n",
      "   Earliest Tweet Date: 07/24/2020\n",
      "   Latest Tweet Date: 08/30/2020\n",
      "\n",
      "Your data is ready for analysis.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "085a84966dfb49829fde7272124834ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Country:', options=('All Countries', 'United States', 'Canada', 'South Africa', 'Switzer…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b97f49ccf27474f8ebbf2cea7113917",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "DatePicker(value=None, description='Start Date', step=1)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ac280b3e7f841a7ac812ea5463678d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "DatePicker(value=None, description='End Date', step=1)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f59ae147f88d43e689d95896364e6431",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Select Plot:', options=('Bar Plot of Most Common Words in Tweets', 'Distribution of Leng…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e359e541dcb441c8a1cb57cd5f1ab92d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Plot', style=ButtonStyle(), tooltip='Plot')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cdf84bc3581416d95f93be1d3ca31de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Demo\n",
    "\n",
    "# Load and process data\n",
    "file_path = input(\"Please enter the path to your CSV file: \")\n",
    "preprocessed_df = load_process_data(file_path)\n",
    "\n",
    "if preprocessed_df is not None:\n",
    "\n",
    "    # Create the widget\n",
    "    plot_dropdown, country_dropdown, start_date_picker, end_date_picker, process_button, output = create_widget()\n",
    "\n",
    "\n",
    "    def on_button_click(b):\n",
    "        with output:\n",
    "            output.clear_output()\n",
    "\n",
    "            # Filter DF based on dropdown / options \n",
    "            filtered_df = filter_df(preprocessed_df, country_dropdown, start_date_picker, end_date_picker)\n",
    "\n",
    "            # Plot selected graph\n",
    "            selected_plot = plot_dropdown.value\n",
    "\n",
    "            if selected_plot == 'Bar Plot of Most Common Words in Tweets':\n",
    "                generate_bar_plot(filtered_df)\n",
    "            elif selected_plot == 'Distribution of Length of Tweets':\n",
    "                generate_tweet_length_plot(filtered_df)\n",
    "            elif selected_plot == 'Time-series Plot of Tweet Counts':\n",
    "                generate_time_series_plot(filtered_df)\n",
    "            elif selected_plot == 'Word Cloud of Most Common Words':\n",
    "                generate_word_cloud(filtered_df)\n",
    "            else: # 'Word Cloud of Most Common Words by Location'\n",
    "                generate_word_cloud_by_location(filtered_df)\n",
    "\n",
    "\n",
    "    process_button.on_click(on_button_click)\n",
    "\n",
    "    #Display widgets\n",
    "\n",
    "    display(country_dropdown)\n",
    "    display(start_date_picker)\n",
    "    display(end_date_picker)\n",
    "    display(plot_dropdown)\n",
    "    display(process_button)\n",
    "    display(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b619db27",
   "metadata": {},
   "source": [
    "## Real Time Inference\n",
    "\n",
    "#### Core Functionality \n",
    "Allow organizations to get real-time labels to categorize recent data.\n",
    "\n",
    "\n",
    "#### Why this matters?\n",
    "This project took a few months, and many more #COVID19 tweets have been created since then, with new protocols, vaccine information, regulation, etc.\n",
    "\n",
    "\n",
    "#### Choices and Impact \n",
    "The organization needs to be able to choose which model they want to use to balance the decisions they make.\n",
    "\n",
    "Even though the performance is similar between our best two models $\\longrightarrow$ they get different results and it's not clear which is best for analysts.\n",
    "\n",
    "In short, <u>we provide the framework to analyze data properly</u>.\n",
    "\n",
    "\n",
    "#### Sample Tweets to try:\n",
    "\n",
    "- #COVID19 cases are on the rise again. Let's all do our part to stop the spread: get vaccinated, wear a mask, and social distance. Together, we can beat this virus.\n",
    "- Indian municipalities have been a great failure in controlling #COVID19 , barring a few.\n",
    "- Coronavirus infections top half a million in South Africa... #SouthAfrica #Gauteng #Pretoria #COVID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dece16a3",
   "metadata": {
    "code_folding": [
     63
    ]
   },
   "outputs": [],
   "source": [
    "# Load in necessary data \n",
    "\n",
    "# Load in embedding model \n",
    "embedding_model = SentenceTransformer('sentence-transformers/all-mpnet-base-v2')\n",
    "\n",
    "# Load in trained models \n",
    "lr = pickle.load(open('../trained_models/lr_v2.pkl', 'rb'))\n",
    "lda = pickle.load(open('../trained_models/lda_v2.pkl', 'rb'))\n",
    "kmeans = pickle.load(open('../trained_models/kmeans.pkl', 'rb'))\n",
    "\n",
    "# Grab the labels from GPT API from Module 2\n",
    "labels_dict = {\n",
    "    0: ['social issues', 'personal development', 'business and economics', 'community building'],\n",
    "    1: ['india', 'updates', 'testing', 'fatalities', 'recoveries', 'healthcare'],\n",
    "    2: ['face masks', 'safety', 'protection', 'public health', 'prevention'],\n",
    "    3: ['social media', 'resilience', 'community support', 'online events'],\n",
    "    4: ['global', 'cases', 'deaths', 'statistics'],\n",
    "    5: ['politics', 'government response', 'public health', 'conspiracy', 'human rights'],\n",
    "    6: ['health', 'information','vacccine', 'public awareness'],\n",
    "    7: ['layoffs', 'misinofrmation', 'mental health', 'lockdown', 'access', 'financial impact', 'political response', 'education']\n",
    "}\n",
    "\n",
    "# Grab the labels from GPT API from Module 2\n",
    "labels = ['social-issues',\n",
    " 'personal-development',\n",
    " 'business-and-economics',\n",
    " 'community-building',\n",
    " 'india',\n",
    " 'updates',\n",
    " 'testing',\n",
    " 'fatalities',\n",
    " 'recoveries',\n",
    " 'healthcare',\n",
    " 'face-masks',\n",
    " 'safety',\n",
    " 'protection',\n",
    " 'public-health',\n",
    " 'prevention',\n",
    " 'social-media',\n",
    " 'resilience',\n",
    " 'community-support',\n",
    " 'online-events',\n",
    " 'global',\n",
    " 'cases',\n",
    " 'deaths',\n",
    " 'statistics',\n",
    " 'politics',\n",
    " 'government-response',\n",
    " 'conspiracy',\n",
    " 'human-rights',\n",
    " 'health',\n",
    " 'information',\n",
    " 'vacccine',\n",
    " 'public-awareness',\n",
    " 'layoffs',\n",
    " 'misinformation',\n",
    " 'mental-health',\n",
    " 'lockdown',\n",
    " 'access',\n",
    " 'financial-impact',\n",
    " 'political-response',\n",
    " 'education']\n",
    "\n",
    "def make_prediction(tweet: str, \n",
    "                    labels: Union[dict, list],\n",
    "                    embedding_model: SentenceTransformer, \n",
    "                    classification_model = None,\n",
    "                    clustering_model = None): \n",
    "    \n",
    "    \"\"\"\n",
    "    Generate a list of predicted labels for an input tweet\n",
    "    \"\"\"\n",
    "    \n",
    "    # Generate the word embedding \n",
    "    embedding = embedding_model.encode(tweet)\n",
    "    embedding = embedding.reshape(1, -1).astype(float)\n",
    "    \n",
    "    # If both there -> return nothing because error\n",
    "    if (clustering_model) and (classification_model):\n",
    "        return None\n",
    "    \n",
    "    # If clustering -> use that\n",
    "    if (clustering_model):\n",
    "        prediction = clustering_model.predict(embedding)\n",
    "        return labels[prediction[0]]\n",
    "    \n",
    "    if (classification_model):\n",
    "        prediction = classification_model.predict(embedding)[0]\n",
    "        return [labels[i] for i in range(len(labels)) if prediction[i] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ec0c91",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Demo\n",
    "\n",
    "# Tweet Input\n",
    "tweet = input(\"Enter a tweet: \")\n",
    "\n",
    "# Select model type \n",
    "options = ['KMeans + GPT API', 'Logistic Regression', 'Linear Discriminant Analysis']\n",
    "dropdown = widgets.Dropdown(options = options,\n",
    "                            value = options[1],\n",
    "                            description = 'Select Model Type: ')\n",
    "\n",
    "# Button to process the dataset and generate the plot\n",
    "button = widgets.Button(description = 'Run Inference', tooltip = 'Run Inference')\n",
    "\n",
    "# Display Result\n",
    "output = widgets.Output()\n",
    "\n",
    "def run_inference(labels, labels_dict, embedding_model, kmeans, lr, lda, verbose = True): \n",
    "    \n",
    "    with output: \n",
    "        \n",
    "        # Clear any existing display\n",
    "        output.clear_output()\n",
    "    \n",
    "        # If clustering\n",
    "        if dropdown.value == options[0]: \n",
    "            labels = make_prediction(tweet = tweet, \n",
    "                                     labels = labels_dict, \n",
    "                                     embedding_model = embedding_model,\n",
    "                                     clustering_model = kmeans, \n",
    "                                     classification_model = None)\n",
    "        elif dropdown.value == options[1]: \n",
    "            labels = make_prediction(tweet = tweet, \n",
    "                                     labels = labels_dict, \n",
    "                                     embedding_model = embedding_model,\n",
    "                                     clustering_model = None, \n",
    "                                     classification_model = lr)\n",
    "            \n",
    "        else:\n",
    "            labels = make_prediction(tweet = tweet, \n",
    "                                     labels = labels,\n",
    "                                     embedding_model = embedding_model,\n",
    "                                     clustering_model = None, \n",
    "                                     classification_model = lda)\n",
    "            \n",
    "        # Print output\n",
    "        if verbose: \n",
    "            print(labels)\n",
    "            \n",
    "        return labels\n",
    "\n",
    "button.on_click(lambda _: run_inference(labels, labels_dict, embedding_model, kmeans, lr, lda))\n",
    "\n",
    "# Display everything \n",
    "display(dropdown)\n",
    "display(button)\n",
    "display(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8553fd78",
   "metadata": {},
   "source": [
    "## User Tweet Micro-Trends\n",
    "\n",
    "#### Core Functionality \n",
    "Allow organizations to understand the micro-trends in indivudal users.\n",
    "\n",
    "\n",
    "#### Why this matters?\n",
    "Health organizations are inextricably linked with politics (for some reason). It's useful for orgs to be able to visualize what highly influential people are talking about in regards to COVID-19.\n",
    "\n",
    "\n",
    "#### Choices and Impact \n",
    "By deciding which users to compare, health organizations can get a sense of the general trends of this user.\n",
    "\n",
    "\n",
    "#### Examples\n",
    "\n",
    "- Shankar Prasad (Minister of Electronics and Information Technology) (try with GPT)\n",
    "- Donald Trump vs Joe Biden (?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe2f7b0",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Demo\n",
    "\n",
    "# Tweet Input\n",
    "username = input(\"Username: \")\n",
    "\n",
    "# Select model type \n",
    "options = ['KMeans + GPT API', 'Logistic Regression', 'Linear Discriminant Analysis']\n",
    "dropdown = widgets.Dropdown(options = options,\n",
    "                            value = options[0],\n",
    "                            description = 'Model: ')\n",
    "\n",
    "# Button to process the dataset and generate the plot\n",
    "button = widgets.Button(description = 'Run Inference', tooltip = 'Run Inference')\n",
    "\n",
    "# Display Result\n",
    "output = widgets.Output()\n",
    "\n",
    "def run_inference(preprocessed_df, labels, labels_dict, embedding_model, kmeans, lr, lda, verbose = True): \n",
    "    \n",
    "    with output: \n",
    "        \n",
    "        # Clear any existing display\n",
    "        output.clear_output()\n",
    "        \n",
    "        # User tweets\n",
    "        user_df = preprocessed_df[preprocessed_df['user_name'] == username]\n",
    "        if len(user_df) > 0:\n",
    "            n_tweets = len(user_df)\n",
    "            user_tweets = user_df.sample(n_tweets)['text']\n",
    "            \n",
    "            vals = []\n",
    "            for tweet in user_tweets: \n",
    "                if dropdown.value == options[0]: \n",
    "                    labels = make_prediction(tweet = tweet, \n",
    "                                             labels = labels_dict, \n",
    "                                             embedding_model = embedding_model,\n",
    "                                             clustering_model = kmeans, \n",
    "                                             classification_model = None)\n",
    "                    vals += labels\n",
    "                elif dropdown.value == options[1]: \n",
    "                    labels = make_prediction(tweet = tweet, \n",
    "                                             labels = labels, \n",
    "                                             embedding_model = embedding_model,\n",
    "                                             clustering_model = None, \n",
    "                                             classification_model = lr)\n",
    "                elif dropdown.value == options[2]: \n",
    "                    labels = make_prediction(tweet = tweet, \n",
    "                                             labels = labels, \n",
    "                                             embedding_model = embedding_model,\n",
    "                                             clustering_model = None, \n",
    "                                             classification_model = lda)\n",
    "                    vals += labels\n",
    "            \n",
    "            \n",
    "            d = pd.Series(vals).value_counts(normalize = True)\n",
    "            print(d)\n",
    "            plt.barh(d.index, d.values)\n",
    "            plt.xlabel('Frequency')\n",
    "            plt.ylabel('Predicted Label')\n",
    "            plt.title(f'Predicted Label Frequency for {username} using {dropdown.value}', pad = 20)\n",
    "\n",
    "button.on_click(lambda _: run_inference(preprocessed_df, labels, labels_dict, embedding_model, kmeans, lr, lda))\n",
    "\n",
    "# Display everything \n",
    "display(dropdown)\n",
    "display(button)\n",
    "display(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ff4f0c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
